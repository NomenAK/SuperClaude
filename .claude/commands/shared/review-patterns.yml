# Review Patterns
# AI-powered code review methodology and quality assessment patterns

## Legend
@include universal-constants.yml#Universal_Legend

## Review_Methodology

```yaml
Review_Framework:
  Evidence_Based_Analysis:
    Source_Validation: "All suggestions must cite authoritative sources"
    Documentation_Links: "Reference official docs via Context7"
    Best_Practice_Verification: "Cross-reference industry standards"
    Metric_Support: "Performance claims require measurable evidence"
    
  Multi_Dimensional_Assessment:
    Code_Quality:
      - "Naming conventions & readability"
      - "Structure & organization patterns"  
      - "DRY principle adherence"
      - "SOLID principles compliance"
      - "Complexity metrics (cyclomatic, cognitive)"
      - "Technical debt identification"
      
    Security_Analysis:
      - "Input validation & sanitization"
      - "Authentication & authorization flows"
      - "Data exposure & privacy concerns"
      - "Injection vulnerability patterns"
      - "Cryptographic implementation review"
      - "Secret management practices"
      
    Performance_Review:
      - "Algorithm complexity analysis"
      - "Database query optimization"
      - "Memory usage patterns"
      - "Caching strategy evaluation"
      - "Resource utilization assessment"
      - "Bottleneck identification"
      
    Architecture_Assessment:
      - "Design pattern appropriateness"
      - "Layer separation & coupling"
      - "Dependency management"
      - "Scalability considerations"
      - "Interface design quality"
      - "Maintainability factors"
      
  Persona_Specialization:
    Security_Focus:
      Priority: ["Vulnerabilities", "Compliance", "Threat modeling", "Risk assessment"]
      Tools: ["Sequential for analysis", "Context7 for security standards"]
      Output: "Threat-aware recommendations with risk ratings"
      
    Performance_Focus:
      Priority: ["Bottlenecks", "Optimization", "Scalability", "Resource efficiency"]
      Tools: ["Sequential for analysis", "Puppeteer for performance testing"]
      Output: "Measurable performance improvements with benchmarks"
      
    Architecture_Focus:
      Priority: ["Design patterns", "Maintainability", "Technical debt", "Scalability"]
      Tools: ["Sequential for complex analysis", "Context7 for patterns"]
      Output: "Long-term architectural recommendations"
      
    QA_Focus:
      Priority: ["Test coverage", "Edge cases", "Quality metrics", "Validation"]
      Tools: ["Puppeteer for testing", "Context7 for testing frameworks"]
      Output: "Comprehensive quality assessment with testing recommendations"
```

## Review_Scope_Patterns

```yaml
File_Review:
  Single_File: "Focused analysis of specific file with context awareness"
  Directory: "Comprehensive review of related files with cross-reference analysis"
  Module: "Complete module assessment with interface evaluation"
  
Commit_Review:
  Single_Commit: "Change-focused analysis with before/after comparison"
  Commit_Range: "Multi-commit analysis with progression tracking"
  Feature_Branch: "Complete feature assessment with integration analysis"
  
Pull_Request_Review:
  Diff_Analysis: "Change-focused review with impact assessment"
  Integration_Review: "Full PR analysis with merge conflict detection"
  Pre_Merge_Validation: "Comprehensive quality gate before merge"
```

## Quality_Metrics

```yaml
Code_Quality_Indicators:
  Complexity_Thresholds:
    Cyclomatic: "Functions >10 flagged, >15 require refactoring"
    Cognitive: "Functions >15 flagged, >25 require redesign"
    Nesting: "More than 4 levels requires simplification"
    
  Maintainability_Factors:
    Line_Count: "Functions >50 lines reviewed for breakdown"
    Parameter_Count: "Functions >5 parameters reviewed for objects"
    Class_Size: "Classes >300 lines reviewed for SRP violations"
    
  Technical_Debt_Indicators:
    Code_Duplication: "Identical blocks >5 lines flagged"
    TODO_Comments: "Track and prioritize technical debt items"
    Dead_Code: "Unused functions and variables identified"
    
Security_Risk_Assessment:
  Critical: "Immediate security vulnerabilities requiring urgent fixes"
  High: "Significant security concerns requiring prompt attention"
  Medium: "Security improvements that should be addressed"
  Low: "Security best practices recommendations"
  
Performance_Benchmarks:
  Response_Time: "API endpoints should respond <200ms"
  Memory_Usage: "Memory leaks and excessive allocations flagged"
  Database_Queries: "N+1 queries and missing indexes identified"
  Bundle_Size: "Frontend bundles >1MB reviewed for optimization"
```

## Output_Standards

```yaml
Review_Report_Structure:
  Executive_Summary:
    - "Overall code quality score"
    - "Critical issues count and severity"
    - "Primary recommendations"
    - "Estimated effort for improvements"
    
  Detailed_Findings:
    Issue_Format:
      - "Location: file:line or commit:hash"
      - "Severity: Critical|High|Medium|Low"
      - "Category: Quality|Security|Performance|Architecture"
      - "Description: Clear explanation of issue"
      - "Evidence: Sources and reasoning"
      - "Recommendation: Specific fix suggestion"
      - "Alternative: Alternative approaches if applicable"
      
  Action_Items:
    - "Prioritized list of improvements"
    - "Estimated effort for each item"
    - "Dependencies between improvements"
    - "Risk assessment for changes"
    
  Knowledge_Base_Updates:
    - "New patterns identified"
    - "Team convention deviations"
    - "Best practice confirmations"
    - "Anti-pattern documentation"
    
File_Storage:
  Review_Reports: ".claudedocs/reviews/review-{timestamp}-{scope}.md"
  Action_Items: ".claudedocs/reviews/actions-{timestamp}.md"
  Metrics_History: ".claudedocs/reviews/metrics-{YYYY-MM-DD}.jsonl"
  Pattern_Library: ".claudedocs/reviews/patterns/{category}-patterns.md"
```

## Integration_Patterns

```yaml
MCP_Server_Usage:
  Context7_Integration:
    Triggers: ["Unknown library usage", "Best practice research", "Documentation lookup"]
    Process: "resolve-library-id → get-docs → extract relevant patterns"
    Output: "Evidence-based recommendations with authoritative sources"
    
  Sequential_Integration:
    Triggers: ["Complex architectural issues", "Multi-step analysis", "Root cause investigation"]
    Process: "Break down complex problems → analyze systematically → provide structured solutions"
    Output: "Comprehensive analysis with step-by-step reasoning"
    
  Magic_Integration:
    Triggers: ["UI component review", "Frontend pattern suggestions", "React/Vue improvements"]
    Process: "Analyze existing components → suggest improvements → generate alternatives"
    Output: "UI-focused recommendations with component examples"
    
  Puppeteer_Integration:
    Triggers: ["E2E test validation", "Performance testing", "UI behavior verification"]
    Process: "Test current implementation → identify issues → validate fixes"
    Output: "Tested recommendations with verification results"
    
Git_Integration:
  Pre_Commit_Hooks: "Automatic quality checks before commits"
  PR_Integration: "Automated review comments on pull requests"
  Branch_Analysis: "Feature branch quality assessment"
  Release_Validation: "Pre-release comprehensive review"
  
Workflow_Integration:
  Development_Cycle: "/review → /improve → /test → /scan → /git"
  Quality_Gate: "/review --evidence → validate → approve/reject"
  Continuous_Improvement: "/review → track metrics → adapt standards"
```

## Learning_Patterns

```yaml
Team_Preference_Learning:
  Style_Preferences:
    Track: "Accepted vs rejected style suggestions"
    Adapt: "Team-specific naming conventions and patterns"
    Store: ".claudedocs/reviews/team-preferences.yml"
    
  Architecture_Patterns:
    Recognize: "Project-specific architectural decisions"
    Document: "Established patterns and anti-patterns"
    Enforce: "Consistency with project architecture"
    
  Quality_Standards:
    Baseline: "Establish team's quality expectations"
    Evolution: "Track quality improvements over time"
    Benchmarks: "Project-specific quality metrics"
    
Feedback_Loop:
  Suggestion_Tracking:
    - "Record which suggestions are implemented"
    - "Track which are rejected and why"
    - "Measure impact of implemented changes"
    - "Adapt future suggestions based on feedback"
    
  Continuous_Improvement:
    - "Regular review of review effectiveness"
    - "Update patterns based on team feedback"
    - "Refine quality thresholds over time"
    - "Evolve review focus areas"
```

---
*Review Patterns v1 - AI-powered code review methodology for SuperClaude framework*